{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855f34bb-ed1e-4161-936b-658da6219e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Using AlexNet on the birds 400 dataset achieved 70% validation accuracy\n",
    "But I was able to achieve higher using resnet pretrained on ImageNet. \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d0ce243-69c6-46b1-996c-d40d8de24717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22885eeb-3bac-4e7f-afe3-3bf481b4bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d23bf4-cfd5-4b89-8b7c-b097ba24ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "trans = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "data_dir = './birds_400'\n",
    "\n",
    "train_ds = ImageFolder(f'{data_dir}/train', transform=trans)\n",
    "test_ds  = ImageFolder(f'{data_dir}/test', transform=trans)\n",
    "valid_ds = ImageFolder(f'{data_dir}/valid', transform=trans)\n",
    "\n",
    "train_dl = DataLoader(train_ds, BATCH_SIZE, shuffle=True, num_workers=3, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds, BATCH_SIZE, shuffle=False, num_workers=3, pin_memory=True)\n",
    "valid_dl = DataLoader(valid_ds, BATCH_SIZE, shuffle=False, num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0197b91e-5612-48d3-81bd-676bbe68db5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001abc05-cc53-48e1-8b57-d1eac45f706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: AlexNet \n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=96,kernel_size=11,stride=4,padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=10e-4, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LocalResponseNorm(size=5, alpha=10e-4, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df97bb5-cb01-4b68-99ac-946a4f9ee3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training at  2022-03-27 23:23:52.567656\n",
      "epoch 1: Train loss: 5.497403131364143 "
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34452/861598732.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mval_acc\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "model = AlexNet(num_classes=400)\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"max\",\n",
    "    factor=0.00001,\n",
    "    patience=2,\n",
    ")\n",
    "\n",
    "# training\n",
    "print(\"Beginning training at \", datetime.now())\n",
    "history = []\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"epoch {epoch+1}: \", end=\"\", flush=True)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (images, labels) in enumerate(train_dl):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(images)\n",
    "        loss = loss_fn(pred, labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    history.append(train_loss / (batch_idx + 1))\n",
    "    print(f\"Train loss: {history[-1]}\", end=\" \", flush=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, val_acc = 0, 0\n",
    "        for batch_idx, (images, labels) in enumerate(valid_dl):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            pred = model(images)\n",
    "            loss = loss_fn(pred, labels)\n",
    "            acc = accuracy(pred, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_acc += acc\n",
    "        val_loss /= batch_idx + 1\n",
    "        val_acc /= batch_idx + 1\n",
    "    scheduler.step(val_acc / (batch_idx + 1))\n",
    "    print(f\"Val loss: {val_loss} Val accuracy: {val_acc}\", flush=True)\n",
    "    if epoch and not (epoch % 5):\n",
    "        print(\"Model saved.\")\n",
    "        torch.save(model, \"./AlexNet_training.model\")\n",
    "print(\"Training ended at \", datetime.now())\n",
    "\n",
    "print(f\"Validation loss: {val_loss}\\nValidation accuracy: {val_acc}\")\n",
    "\n",
    "\n",
    "torch.save(model, \"./lrn_AlexNet.model\")\n",
    "print(\"Model has been saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27a2b5-a58d-4ea5-8b3b-e951c1d535bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec6015-0a4e-4de5-9c53-87e7f6c2ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2eb6b9-d7d6-415c-8503-a89212afe8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b2b01-3072-46fe-a555-fc0b90c3898c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f292b4-6a48-4d63-95db-a22d56c738ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
